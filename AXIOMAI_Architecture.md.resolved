# FactFlow — Project Architecture & Agents

## 1. Project Structure

```text
FactFlow/
├── backend/
│   ├── app/
│   │   ├── agents/
│   │   │   └── generator.py        # LLM Generation logic
│   │   ├── core/
│   │   │   ├── config.py           # Environment & Settings
│   │   │   └── prompts.py          # System prompt templates
│   │   ├── orchestration/
│   │   │   └── graph.py            # LangGraph pipeline definition
│   │   ├── rag/
│   │   │   ├── hallucination.py    # Claim-level verification
│   │   │   ├── refresh.py          # Vector DB re-indexing
│   │   │   ├── retriever.py        # Pinecone vector search
│   │   │   ├── validator.py        # Trust Score computation
│   │   │   └── watcher.py          # Background staleness detection
│   │   └── main.py                 # FastAPI application (planned)
│   ├── create_index.py             # Pinecone initialization script
│   ├── main.py                     # Entry point (CLI testing)
│   ├── requirements.txt            # Project dependencies
│   └── .env                         # API keys (Gemini, Pinecone)
├── docs/
│   ├── PROJECT_BLUEPRINT.md        # Comprehensive design doc
│   └── trust_score_logic.md        # Math behind trust evaluation
├── Project_info.txt                # Quick reference & Tech stack
└── data/                           # (Planned) Raw document store
```

---

## 2. Agent Introductions

FactFlow uses a modular multi-agent system where each agent has one specific responsibility:

1.  **Retriever Agent ([retriever.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/rag/retriever.py))**:
    *   **Role**: Context Finder.
    *   **Logic**: Uses HuggingFace BGE embeddings to perform semantic search in Pinecone. It cleans the query and fetches the top-K most relevant document chunks.

2.  **LLM Generator Agent ([generator.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/agents/generator.py))**:
    *   **Role**: Answer Composer.
    *   **Logic**: Uses Google Gemini (1.5 Flash). It takes the retrieved chunks and the user query to draft a grounded response, ensuring it sticks to the provided context.

3.  **Answer Validator Agent ([validator.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/rag/validator.py))**:
    *   **Role**: Quality Assurance.
    *   **Logic**: Computes a **Trust Score** (0–1). It weights semantic similarity (40%), source diversity (30%), and document freshness (30%). It decides if an answer is "Trusted" or needs further checking.

4.  **Hallucination Detector Agent ([hallucination.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/rag/hallucination.py))**:
    *   **Role**: Fact Checker.
    *   **Logic**: Decomposes the answer into individual sentences (claims). It verified each claim against the retrieved docs using cosine similarity. If a claim lacks support, it flags a "hallucination."

5.  **Knowledge Refresh Agent ([refresh.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/rag/refresh.py))**:
    *   **Role**: Self-Healer.
    *   *Logic**: Triggered when hallucinations are found or documents are stale. It re-embeds the problematic documents and updates the Pinecone index to fix the knowledge gap.

6.  **Document Watcher Agent ([watcher.py](file:///d:/D/sem_6/SGP-II/FactFlow/backend/app/rag/watcher.py))**:
    *   **Role**: Background Monitor.
    *   **Logic**: Compares content SHA256 hashes and publication timestamps. If a document has changed or passed its freshness threshold (180 days), it marks it for a refresh.

---

## 3. How the System Works (The Workflow)

The system is orchestrated using **LangGraph**, which treats the RAG pipeline as a stateful graph (finite state machine):

1.  **Entry (Retrieve)**: The process starts by retrieving relevant documents from Pinecone.
2.  **Synthesis (Generate)**: Gemini generates an answer based on those documents.
3.  **Verification (Validate)**: The Validator computes the Trust Score.
    *   **Path A (Trusted)**: If the score is high (≥ 0.65), the system returns the answer + citations immediately.
    *   **Path B (Untrusted)**: If the score is low, the flow moves to the **Hallucination Detector**.
4.  **Fact-Checking (Hallucination)**:
    *   If **Hallucination is Detected**: The flow goes to the **Knowledge Refresh Agent** to update the index, then **loops back to Retrieval** to try again (max 2 retries).
    *   If **No Hallucination Found**: Even though the score was low, the claims are technically supported. The system returns the answer but with a **Low-Confidence Warning**.
5.  **Exit**: The final state (answer, trust score, citations, and status) is delivered to the user.

> This circular architecture ensures that if the system identifies its own mistake (via hallucination detection), it attempts to correct its knowledge automatically before giving up.
