# AXIOMAI â€” Complete Project Blueprint

---

## 1. PRODUCT OVERVIEW

### What It Does
AXIOMAI is a **production-grade, agentic Retrieval-Augmented Generation (RAG) system** that answers user queries by retrieving information from ingested documents, generating LLM-powered answers, and then rigorously validating those answers before delivering them. Unlike basic RAG implementations, AXIOMAI treats every answer as "untrusted until proven otherwise." It computes a Trust Score, detects hallucinations at the claim level, and can autonomously refresh stale knowledge â€” all driven by a multi-agent architecture where each agent has a single, well-defined responsibility. The system is designed for domains where accuracy is non-negotiable: legal research, medical references, compliance, education, and enterprise knowledge bases.

### Target Users
| Attribute | Detail |
|---|---|
| **Primary** | Enterprise knowledge teams, compliance officers, legal/medical researchers (30â€“55, non-technical to semi-technical) |
| **Secondary** | AI/ML engineers building trustworthy RAG pipelines (25â€“40, highly technical) |
| **Tertiary** | EdTech platforms needing verified Q&A over course material |
| **Geography** | Global, English-first |

### Core Problem
LLMs hallucinate. Standard RAG pipelines silently pass low-confidence or fabricated answers. In high-stakes domains (legal, medical, compliance), a single wrong answer can cause lawsuits, regulatory fines, or patient harm. **There is no mainstream, open-source RAG system that treats trust as a first-class citizen with automated hallucination detection and self-healing knowledge.**

### Real-World Use Cases
1. **Legal firm** ingests 500+ case law PDFs â†’ lawyers query in natural language â†’ get cited, trust-scored answers
2. **Hospital** ingests clinical guidelines â†’ doctors verify drug interactions â†’ system refuses to answer if evidence is insufficient
3. **University** ingests course materials â†’ students ask questions â†’ system cites exact pages, flags outdated syllabi
4. **Compliance team** ingests regulatory docs â†’ auditors query policy â†’ system auto-refreshes when regulations update

### User Journey
```
Sign Up â†’ Upload Documents â†’ System Indexes (Vector DB)
    â†’ User Asks Question â†’ Retrieval â†’ Generation â†’ Validation
        â†’ IF trusted: Answer + Citations + Trust Score
        â†’ IF untrusted: Hallucination Detection â†’ Flag/Refuse
        â†’ IF stale: Auto-Refresh â†’ Re-answer
    â†’ User reviews answer with confidence level
```

---

## 2. FEATURE BREAKDOWN

### Must-Have (MVP)
| Feature | Status |
|---|---|
| Document ingestion (PDF, TXT) | âœ… Done |
| Vector embedding + Pinecone storage | âœ… Done |
| Query â†’ Retrieve â†’ Generate pipeline | âœ… Done |
| Trust Score computation (similarity + sources + freshness) | âœ… Done |
| Hallucination detection (claim-level verification) | âœ… Done |
| Knowledge Refresh Agent (partial/full re-index) | âœ… Done |
| Document Watcher (hash + timestamp staleness) | âœ… Done |
| Structured output contract (answer, citations, trust, status) | ğŸ”² Pending |
| Query Preprocessor (cleaning, intent detection) | ğŸ”² Pending |

### Good-to-Have
- Answer caching (avoid re-generating identical queries)
- Conversation memory (multi-turn Q&A)
- Source highlighting (show exact passages used)
- Batch document ingestion with progress tracking
- Export answers as PDF reports

### Advanced / Future
- Multi-modal RAG (images, tables in PDFs)
- Fine-tuned domain embeddings
- Feedback loop (user thumbs-up/down improves ranking)
- A/B testing of different LLM providers
- Real-time document streaming (RSS, webhooks)
- Multi-tenant isolation

### Admin Features
- Dashboard: ingestion status, query volume, trust score distribution
- Document management: add/remove/re-index
- System health: agent latency, error rates
- User management and API key provisioning

### Edge Cases
- Empty vector DB (no documents indexed) â†’ graceful "no context" response âœ… Handled
- Document with no text (scanned image PDF) â†’ needs OCR preprocessing
- Extremely long documents â†’ chunking strategy matters
- Conflicting sources â†’ trust score should reflect disagreement
- Rate-limited LLM API â†’ queue + retry logic
- Pinecone index dimension mismatch after model change â†’ migration needed

---

## 3. TECHNICAL ARCHITECTURE

### Frontend Stack (Future)
| Choice | Why |
|---|---|
| **Next.js 14+ (App Router)** | SSR for SEO, React ecosystem, API routes built-in |
| **Tailwind CSS** | Rapid prototyping, consistent design |
| **shadcn/ui** | Accessible, composable components |
| **Zustand** | Lightweight state management |

### Backend Stack (Current)
| Choice | Why |
|---|---|
| **Python 3.11** | ML/AI ecosystem, LangChain compatibility |
| **LangChain** | Agent abstraction, prompt management, embeddings |
| **FastAPI** (planned) | Async, auto-docs, type-safe |
| **Google Gemini (gemini-1.5-flash)** | Cost-effective, fast, good quality |
| **Pinecone (Serverless)** | Managed vector DB, scales to zero |
| **HuggingFace BGE-small** | Local embeddings, no API cost |

### Database Design

#### Pinecone Vector Store
```
Index: "axiomai" (dimension: 384, metric: cosine)
â”œâ”€â”€ Vector ID: doc_chunk_{hash}
â”œâ”€â”€ Values: [384-dim embedding]
â””â”€â”€ Metadata:
    â”œâ”€â”€ content: str
    â”œâ”€â”€ source: str (filename)
    â”œâ”€â”€ page: int
    â”œâ”€â”€ content_hash: str (SHA256)
    â”œâ”€â”€ published_at: str (ISO 8601)
    â””â”€â”€ ingested_at: str (ISO 8601)
```

#### Future: PostgreSQL (operational data)
```
users          (id, email, role, api_key, created_at)
documents      (id, filename, status, chunk_count, ingested_at)
queries        (id, user_id, query_text, trust_score, decision, created_at)
refresh_logs   (id, reason, refresh_type, doc_count, timestamp)
```

### Authentication
- **Phase 1**: API key-based (simple, sufficient for internal/demo)
- **Phase 2**: JWT + OAuth 2.0 (Google/GitHub SSO)
- **Phase 3**: Role-based access control (admin, user, viewer)

### API Structure (Planned)
```
POST /api/v1/query          â†’ Ask a question
POST /api/v1/ingest         â†’ Upload documents
GET  /api/v1/documents      â†’ List indexed documents
POST /api/v1/refresh        â†’ Trigger manual refresh
GET  /api/v1/health         â†’ System status
GET  /api/v1/metrics        â†’ Trust score distribution
```

### State Management
- **Backend**: Stateless request handling; agent state lives in function scope
- **Frontend** (future): Zustand for query history, active filters, UI state

### Caching Strategy
- **Embedding cache**: HuggingFace local model cache (`~/.cache/huggingface/`)
- **Query cache** (future): Redis â€” hash(query) â†’ cached answer (TTL: 1 hour)
- **Document hash cache**: In-memory dict during watcher runs

### File Storage
- **Local**: `backend/data/` for raw source documents
- **Future**: S3/GCS bucket with signed URLs for upload/download

---

## 4. SYSTEM DESIGN

### High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessorâ”‚ â† Clean, normalize, detect intent
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Retriever  â”‚â”€â”€â”€â”€â–¶â”‚  Pinecone DB â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generator   â”‚â”€â”€â”€â”€â–¶â”‚  Gemini LLM  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validator   â”‚ â† Trust Score (0â€“1)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ Trusted â”€â”€â–¶ Return Answer + Citations
       â”‚
       â””â”€â”€â”€ Untrusted â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Hallucination Det.  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Knowledge Refresh   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–²
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Document Watcher    â”‚ (Background)
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow
1. Query enters â†’ cleaned by Preprocessor
2. Preprocessor output â†’ embedded â†’ top-K retrieval from Pinecone
3. Retrieved chunks + query â†’ Gemini generates draft answer
4. Draft answer + chunks â†’ Validator computes Trust Score
5. If trusted â†’ structured response returned
6. If untrusted â†’ Hallucination Detector splits into claims, verifies each
7. Document Watcher periodically checks for hash/timestamp staleness
8. If stale â†’ Knowledge Refresh Agent re-indexes affected documents

### Scalability
| Concern | Solution |
|---|---|
| Embedding bottleneck | Batch embedding, GPU acceleration, or switch to API-based embeddings |
| Pinecone limits | Serverless auto-scales; shard by namespace for multi-tenant |
| LLM rate limits | Queue with exponential backoff; provider fallback (Gemini â†’ OpenAI) |
| Concurrent queries | FastAPI async handlers; horizontal pod scaling |

### Security
- API keys stored in `.env`, never committed (`.gitignore` âœ…)
- Input sanitization in Preprocessor (prevent prompt injection)
- Output filtering (no PII leakage from documents)
- HTTPS-only in production
- Pinecone API key rotation policy

### Rate Limiting
- Per-user: 60 queries/minute
- Per-IP: 100 requests/minute
- Global: Circuit breaker on LLM API failures

### Logging & Monitoring
- **Current**: Print-based logging with timestamps âœ…
- **Phase 2**: Python `logging` module â†’ structured JSON logs
- **Phase 3**: ELK stack or Datadog; alert on trust score degradation

---

## 5. DEPLOYMENT STRATEGY

### Hosting Options
| Option | Cost | Best For |
|---|---|---|
| **Railway / Render** | $5â€“25/mo | MVP, demo, small teams |
| **AWS (ECS + Lambda)** | $20â€“100/mo | Production, scalability |
| **GCP Cloud Run** | Pay-per-use | Cost-optimized, auto-scale |
| **Self-hosted (Docker)** | Hardware cost | Enterprise, data sovereignty |

### CI/CD
```
GitHub Push â†’ GitHub Actions
    â”œâ”€â”€ Lint (ruff/flake8)
    â”œâ”€â”€ Test (pytest)
    â”œâ”€â”€ Build Docker image
    â””â”€â”€ Deploy to staging â†’ manual promote to prod
```

### Environments
| Environment | Purpose | Database |
|---|---|---|
| `dev` | Local development | Pinecone dev index |
| `staging` | Pre-release testing | Pinecone staging index |
| `prod` | Live users | Pinecone prod index |

### Versioning
- **API**: URL-based (`/api/v1/`, `/api/v2/`)
- **Code**: Semantic versioning (`v1.2.3`)
- **Git**: Feature branches â†’ PR â†’ `main`

---

## 6. MONETIZATION MODEL

### Pricing Strategy
| Tier | Queries/mo | Documents | Price |
|---|---|---|---|
| **Free** | 50 | 10 | $0 |
| **Pro** | 1,000 | 100 | $29/mo |
| **Team** | 10,000 | 500 | $99/mo |
| **Enterprise** | Unlimited | Unlimited | Custom |

### Free vs Paid Limits
- Free: BGE-small embeddings, basic trust score, 5 chunks/query
- Paid: Choice of embedding model, full hallucination detection, 20 chunks/query, priority refresh

### Growth Strategy
1. Open-source the core agents (community + credibility)
2. Offer hosted version with managed Pinecone + LLM
3. Enterprise: On-premise deployment, custom integrations, SLA
4. Content marketing: "Why RAG without trust scoring is dangerous"

---

## 7. RISKS & FAILURE POINTS

### Technical Risks
| Risk | Severity | Mitigation |
|---|---|---|
| LLM API downtime | High | Provider fallback chain |
| Pinecone outage | High | Local FAISS fallback |
| Embedding model deprecation | Medium | Abstract embedding layer |
| Prompt injection attacks | High | Input sanitization + output filtering |

### Product Risks
- Users may not understand trust scores â†’ need clear UX explanations
- "Refused" answers frustrate users â†’ need graceful degradation
- Document ingestion friction â†’ need drag-and-drop UI

### Scaling Risks
- Embedding large document sets is slow locally â†’ need GPU or API embeddings
- Re-indexing 10K+ documents takes hours â†’ need background job queue
- Multi-tenant data isolation is complex â†’ namespace strategy

### Legal / Privacy Risks
- Documents may contain PII â†’ need data processing agreement
- GDPR: Right to deletion must cascade to vector DB
- Medical/legal domains may require compliance certifications

---

## 8. DEVELOPMENT ROADMAP

### Phase 1 â€” Core Agents âœ… (Done)
- [x] Retriever Agent
- [x] Generator Agent (Gemini)
- [x] Validator Agent (Trust Score)
- [x] Hallucination Detector Agent
- [x] Knowledge Refresh Agent
- [x] Document Watcher Agent
- [x] PDF ingestion pipeline

### Phase 2 â€” Production Hardening (Weeks 3â€“4)
- [ ] Query Preprocessor Agent (cleaning + intent detection)
- [ ] Agent Orchestrator (graph-based workflow with loops)
- [ ] Structured output contract enforcement
- [ ] FastAPI endpoints
- [ ] Error handling + retries
- [ ] Logging upgrade (structured JSON)
- [ ] Unit tests for all agents

### Phase 3 â€” Frontend & Deployment (Weeks 5â€“6)
- [ ] Next.js frontend with query UI
- [ ] Document upload interface
- [ ] Trust score visualization
- [ ] Docker containerization
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Deploy to staging

### Phase 4 â€” Launch (Week 7â€“8)
- [ ] Security audit (prompt injection, PII)
- [ ] Performance benchmarking
- [ ] Documentation (API docs, user guide)
- [ ] Landing page
- [ ] Beta launch with 10 users

### Final Launch Checklist
- [ ] All agents tested independently and end-to-end
- [ ] `.env` secrets rotated for production
- [ ] HTTPS configured
- [ ] Rate limiting active
- [ ] Monitoring dashboards live
- [ ] Backup strategy for document store
- [ ] GDPR/privacy policy published

---

## 9. METRICS TO TRACK

### Technical Metrics
| Metric | Target |
|---|---|
| P95 query latency | < 3 seconds |
| Trust score distribution | Mean > 0.7 |
| Hallucination detection rate | > 90% recall |
| Knowledge refresh frequency | < 1/day (stable) |
| Uptime | 99.5% |

### Business Metrics
| Metric | Target |
|---|---|
| Monthly active users | 100 (month 3) |
| Queries per user per day | > 5 |
| Conversion (free â†’ paid) | > 5% |
| Churn rate | < 10%/mo |

### User Engagement Metrics
| Metric | What It Tells You |
|---|---|
| Queries per session | Are users finding value? |
| % of "refused" answers | Is the system too strict? |
| Document upload frequency | Are users investing in the platform? |
| Trust score click-through | Do users understand/care about trust? |

---

## 10. BRUTALLY HONEST CRITIQUE

### Is This Idea Weak?
**No.** The problem is real and growing. Every enterprise adopting LLMs will hit the hallucination wall. The market timing is excellent (2025â€“2026 is the "reliability era" of AI).

### Where Will It Likely Fail?
1. **User experience**: If the trust score UX is confusing, users will ignore it
2. **Too many "refused" answers**: Users will switch to ChatGPT which "just answers"
3. **Document ingestion friction**: If uploading and indexing is painful, users won't onboard
4. **Performance**: 3+ second latency for a simple question will frustrate users

### Competitors
| Competitor | Strength | AXIOMAI's Edge |
|---|---|---|
| **Perplexity AI** | Fast, great UX | No trust scoring, no custom docs |
| **Azure AI Search** | Enterprise-grade | Expensive, vendor lock-in |
| **LlamaIndex** | Great framework | Framework, not a product; no trust layer |
| **Verba (Weaviate)** | Open-source RAG | No hallucination detection |
| **Vectara** | Managed RAG API | Closed-source, no self-healing |

### How to Differentiate
1. **Trust Score is the moat** â€” no competitor has a transparent, configurable trust metric
2. **Self-healing knowledge** â€” auto-refresh when documents change is unique
3. **Claim-level hallucination detection** â€” goes beyond simple similarity checks
4. **Open-source core + hosted product** â€” best of both worlds
5. **Domain-specific templates** â€” pre-configured for legal, medical, education

---

> *"The best RAG system is one that knows when it doesn't know."*
> â€” AXIOMAI Design Philosophy
